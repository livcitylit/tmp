{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "APIs and scraping for stock data",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTYi77H2LnvO6e7TIJFQbF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/livcitylit/tmp/blob/master/Stock%20project/Week%202/APIs_and_scraping_for_stock_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrJnsXjxgGxa"
      },
      "source": [
        "# 1 - Yahoo finance API (Application programming interface)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxKIu3IObJvr"
      },
      "source": [
        "Ever since Yahoo! finance decommissioned their historical data API, many programs that relied on it to stop working.\n",
        "\n",
        "yfinance aimes to solve this problem by offering a reliable, threaded, and Pythonic way to download historical market data from Yahoo! finance.\n",
        "It is open source and free to use. \n",
        "\n",
        "You will find that this API arbitrarily slows down and speeds up when you are downloading lots of data. This is intentional, so that Yahoo finance doesn't flag you for scraping. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oj6Bl3TbCtq",
        "outputId": "ee2c4169-d8ca-4f26-d44e-258b59333c22"
      },
      "source": [
        "!pip install yfinance as yfinance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/e8/b9d7104d3a4bf39924799067592d9e59119fcfc900a425a12e80a3123ec8/yfinance-0.1.55.tar.gz\n",
            "Collecting as\n",
            "  Downloading https://files.pythonhosted.org/packages/b4/08/226c133ec497d25a63edb38527c02db093c7d89e6d4cdc91078834486a5d/as-0.1-py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.1.4)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from yfinance) (1.18.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.6/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/28/0b761b64ecbd63d272ed0e7a6ae6e4402fc37886b59181bfdf274424d693/lxml-4.6.1-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20->yfinance) (2020.11.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.55-py2.py3-none-any.whl size=22618 sha256=14d6ba70bd602d902dd7589da7c9e8a9e36b886a0d91c8bd8d71b0d4f69701a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/98/cc/2702a4242d60bdc14f48b4557c427ded1fe92aedf257d4565c\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance, as\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed as-0.1 lxml-4.6.1 yfinance-0.1.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWufIrnKbFiU"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzKN56Zcbiup"
      },
      "source": [
        "On the stock market, each company has an abbreviation they are identified. These are known as tickers. This is how we refer to the companies on yahoo finance. The ones that are traded on the London stock exchange have a .L at the end. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQzEv8HJbeB1"
      },
      "source": [
        "# we now store the information from this ticker inside the variable tesco\n",
        "\n",
        "tesco = yf.Ticker(\"TSCO.L\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2kc1yI4cYH_"
      },
      "source": [
        "tesco.info will give us a dictionary with the overall info for the company. Here we have very important information like the market cap (How much money could one maximum make in the market of this company), netIncome, previous close price - i.e. what was the stock price last time the market closed, profit margin, volume traded and much more. If you need a refresher on dictionaries, you'll find some resources on the google classroom. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olxxJSKabvvD",
        "outputId": "377585be-1308-4061-cf55-be05934d0747"
      },
      "source": [
        "tesco.info"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'52WeekChange': -0.00042957067,\n",
              " 'SandP52WeekChange': 0.13917124,\n",
              " 'address1': 'Tesco House',\n",
              " 'address2': 'Shire Park Kestrel Way',\n",
              " 'algorithm': None,\n",
              " 'annualHoldingsTurnover': None,\n",
              " 'annualReportExpenseRatio': None,\n",
              " 'ask': 227.1,\n",
              " 'askSize': 0,\n",
              " 'averageDailyVolume10Day': 44695995,\n",
              " 'averageVolume': 25159565,\n",
              " 'averageVolume10days': 44695995,\n",
              " 'beta': 0.300632,\n",
              " 'beta3Year': None,\n",
              " 'bid': 226.9,\n",
              " 'bidSize': 0,\n",
              " 'bookValue': 1.253,\n",
              " 'category': None,\n",
              " 'circulatingSupply': None,\n",
              " 'city': 'Welwyn Garden City',\n",
              " 'companyOfficers': [],\n",
              " 'country': 'United Kingdom',\n",
              " 'currency': 'GBp',\n",
              " 'dateShortInterest': None,\n",
              " 'dayHigh': 228.5,\n",
              " 'dayLow': 226.2,\n",
              " 'dividendRate': 0.1,\n",
              " 'dividendYield': 0.0417,\n",
              " 'earningsQuarterlyGrowth': 0.42,\n",
              " 'enterpriseToEbitda': 8.97,\n",
              " 'enterpriseToRevenue': 0.557,\n",
              " 'enterpriseValue': 36185833472,\n",
              " 'exDividendDate': 1602720000,\n",
              " 'exchange': 'LSE',\n",
              " 'exchangeTimezoneName': 'Europe/London',\n",
              " 'exchangeTimezoneShortName': 'GMT',\n",
              " 'expireDate': None,\n",
              " 'fiftyDayAverage': 216.92285,\n",
              " 'fiftyTwoWeekHigh': 332.67,\n",
              " 'fiftyTwoWeekLow': 202,\n",
              " 'fiveYearAverageReturn': None,\n",
              " 'fiveYearAvgDividendYield': None,\n",
              " 'floatShares': 9504005280,\n",
              " 'forwardEps': 16.73,\n",
              " 'forwardPE': 0.13574418,\n",
              " 'fromCurrency': None,\n",
              " 'fullTimeEmployees': 405506,\n",
              " 'fundFamily': None,\n",
              " 'fundInceptionDate': None,\n",
              " 'gmtOffSetMilliseconds': '0',\n",
              " 'heldPercentInsiders': 0.02263,\n",
              " 'heldPercentInstitutions': 0.63046,\n",
              " 'industry': 'Grocery Stores',\n",
              " 'isEsgPopulated': False,\n",
              " 'lastCapGain': None,\n",
              " 'lastDividendDate': 1602720000,\n",
              " 'lastDividendValue': 3.2,\n",
              " 'lastFiscalYearEnd': 1582934400,\n",
              " 'lastMarket': None,\n",
              " 'lastSplitDate': 899683200,\n",
              " 'lastSplitFactor': '3:1',\n",
              " 'legalType': None,\n",
              " 'logo_url': 'https://logo.clearbit.com/tescoplc.com',\n",
              " 'longBusinessSummary': 'Tesco PLC, together with its subsidiaries, operates as a grocery retailer. The company operates through convenience and hypermarket store formats, as well as engages in the wholesale business. It also provides retail banking and insurance services. The company operates in the United Kingdom, the Republic of Ireland, the Czech Republic, Hungary, Poland, Slovakia, Malaysia, and Thailand. The company serves its customers through stores, as well as online. Tesco PLC was founded in 1919 and is headquartered in Welwyn Garden City, the United Kingdom.',\n",
              " 'longName': 'Tesco PLC',\n",
              " 'market': 'gb_market',\n",
              " 'marketCap': 22241038336,\n",
              " 'maxAge': 1,\n",
              " 'maxSupply': None,\n",
              " 'messageBoardId': 'finmb_413744',\n",
              " 'morningStarOverallRating': None,\n",
              " 'morningStarRiskRating': None,\n",
              " 'mostRecentQuarter': 1598659200,\n",
              " 'navPrice': None,\n",
              " 'netIncomeToCommon': 1030000000,\n",
              " 'nextFiscalYearEnd': 1646092800,\n",
              " 'open': 227.8,\n",
              " 'openInterest': None,\n",
              " 'payoutRatio': 0.86480004,\n",
              " 'pegRatio': None,\n",
              " 'phone': '44 19 9263 2222',\n",
              " 'previousClose': 227.8,\n",
              " 'priceHint': 2,\n",
              " 'priceToBook': 181.24501,\n",
              " 'priceToSalesTrailing12Months': 0.3423489,\n",
              " 'profitMargins': 0.01704,\n",
              " 'quoteType': 'EQUITY',\n",
              " 'regularMarketDayHigh': 228.5,\n",
              " 'regularMarketDayLow': 226.2,\n",
              " 'regularMarketOpen': 227.8,\n",
              " 'regularMarketPreviousClose': 227.8,\n",
              " 'regularMarketPrice': 227.8,\n",
              " 'regularMarketVolume': 19659352,\n",
              " 'revenueQuarterlyGrowth': None,\n",
              " 'sector': 'Consumer Defensive',\n",
              " 'sharesOutstanding': 9793500160,\n",
              " 'sharesPercentSharesOut': None,\n",
              " 'sharesShort': None,\n",
              " 'sharesShortPreviousMonthDate': None,\n",
              " 'sharesShortPriorMonth': None,\n",
              " 'shortName': 'TESCO PLC ORD 5P',\n",
              " 'shortPercentOfFloat': None,\n",
              " 'shortRatio': None,\n",
              " 'startDate': None,\n",
              " 'strikePrice': None,\n",
              " 'symbol': 'TSCO.L',\n",
              " 'threeYearAverageReturn': None,\n",
              " 'toCurrency': None,\n",
              " 'totalAssets': None,\n",
              " 'tradeable': False,\n",
              " 'trailingAnnualDividendRate': 0.097,\n",
              " 'trailingAnnualDividendYield': 0.00042581212,\n",
              " 'trailingEps': 11.3,\n",
              " 'trailingPE': 20.097345,\n",
              " 'twoHundredDayAverage': 222.08723,\n",
              " 'volume': 19659352,\n",
              " 'volume24Hr': None,\n",
              " 'volumeAllCurrencies': None,\n",
              " 'website': 'http://www.tescoplc.com',\n",
              " 'yield': None,\n",
              " 'ytdReturn': None,\n",
              " 'zip': 'AL7 1GA'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ESWNuoZdDWk"
      },
      "source": [
        "We can use the command history to have a look at the historic prices for the market. Open is the price of the stock when the market opened on a given day, and close what it was when it closed. It shows the highest and lowest price for the day. It also shows the volume of the stock traded that day. It also shows the dividends - this is a payment to shareholders. Sometimes stocks are also split, like Tesla did recently, and this is shown here as well. You can specify the period, or intervals for which you want data within the history argument. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "0xlxFBWhc-Eq",
        "outputId": "5476c6ae-cb8f-4864-db6e-7a1e0b049733"
      },
      "source": [
        "tesco.history(period='max')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1988-07-01</th>\n",
              "      <td>16.005281</td>\n",
              "      <td>16.005281</td>\n",
              "      <td>16.005281</td>\n",
              "      <td>16.005281</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988-07-04</th>\n",
              "      <td>15.691253</td>\n",
              "      <td>15.691253</td>\n",
              "      <td>15.691253</td>\n",
              "      <td>15.691253</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988-07-05</th>\n",
              "      <td>15.900496</td>\n",
              "      <td>15.900496</td>\n",
              "      <td>15.900496</td>\n",
              "      <td>15.900496</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988-07-06</th>\n",
              "      <td>15.691253</td>\n",
              "      <td>15.691253</td>\n",
              "      <td>15.691253</td>\n",
              "      <td>15.691253</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988-07-07</th>\n",
              "      <td>15.377544</td>\n",
              "      <td>15.377544</td>\n",
              "      <td>15.377544</td>\n",
              "      <td>15.377544</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-18</th>\n",
              "      <td>227.399994</td>\n",
              "      <td>233.800003</td>\n",
              "      <td>225.699997</td>\n",
              "      <td>233.199997</td>\n",
              "      <td>41037018</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-19</th>\n",
              "      <td>232.300003</td>\n",
              "      <td>238.671005</td>\n",
              "      <td>232.300003</td>\n",
              "      <td>236.100006</td>\n",
              "      <td>38715085</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-20</th>\n",
              "      <td>235.300003</td>\n",
              "      <td>236.100006</td>\n",
              "      <td>231.199997</td>\n",
              "      <td>232.699997</td>\n",
              "      <td>24921164</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-23</th>\n",
              "      <td>232.199997</td>\n",
              "      <td>232.500000</td>\n",
              "      <td>227.199997</td>\n",
              "      <td>227.800003</td>\n",
              "      <td>29437772</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-11-24</th>\n",
              "      <td>227.800003</td>\n",
              "      <td>228.500000</td>\n",
              "      <td>226.199997</td>\n",
              "      <td>227.100006</td>\n",
              "      <td>19659352</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8313 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Open        High  ...  Dividends  Stock Splits\n",
              "Date                                ...                         \n",
              "1988-07-01   16.005281   16.005281  ...        0.0           0.0\n",
              "1988-07-04   15.691253   15.691253  ...        0.0           0.0\n",
              "1988-07-05   15.900496   15.900496  ...        0.0           0.0\n",
              "1988-07-06   15.691253   15.691253  ...        0.0           0.0\n",
              "1988-07-07   15.377544   15.377544  ...        0.0           0.0\n",
              "...                ...         ...  ...        ...           ...\n",
              "2020-11-18  227.399994  233.800003  ...        0.0           0.0\n",
              "2020-11-19  232.300003  238.671005  ...        0.0           0.0\n",
              "2020-11-20  235.300003  236.100006  ...        0.0           0.0\n",
              "2020-11-23  232.199997  232.500000  ...        0.0           0.0\n",
              "2020-11-24  227.800003  228.500000  ...        0.0           0.0\n",
              "\n",
              "[8313 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hnPv37PEd6GF",
        "outputId": "f9a08abe-cc68-4365-efa9-291bc5e23834"
      },
      "source": [
        "tesco.actions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1993-04-19</th>\n",
              "      <td>4.85</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993-10-04</th>\n",
              "      <td>2.45</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-04-25</th>\n",
              "      <td>5.30</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1994-09-26</th>\n",
              "      <td>2.70</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-04-24</th>\n",
              "      <td>5.90</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-09-25</th>\n",
              "      <td>3.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-04-22</th>\n",
              "      <td>6.55</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996-09-23</th>\n",
              "      <td>3.25</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997-04-14</th>\n",
              "      <td>7.10</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997-09-22</th>\n",
              "      <td>3.55</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-04-27</th>\n",
              "      <td>8.05</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-07-06</th>\n",
              "      <td>0.00</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998-09-29</th>\n",
              "      <td>1.25</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999-04-19</th>\n",
              "      <td>2.87</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999-09-27</th>\n",
              "      <td>1.34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-04-17</th>\n",
              "      <td>3.14</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-09-25</th>\n",
              "      <td>1.48</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-04-18</th>\n",
              "      <td>3.50</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001-09-26</th>\n",
              "      <td>1.67</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-04-17</th>\n",
              "      <td>3.93</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2002-09-25</th>\n",
              "      <td>1.87</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-04-16</th>\n",
              "      <td>4.33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-09-24</th>\n",
              "      <td>2.07</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-04-28</th>\n",
              "      <td>4.77</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2004-09-29</th>\n",
              "      <td>2.29</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-04-20</th>\n",
              "      <td>5.27</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2005-09-28</th>\n",
              "      <td>2.53</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-05-03</th>\n",
              "      <td>6.10</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-10-11</th>\n",
              "      <td>2.81</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-04-25</th>\n",
              "      <td>6.83</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-10-10</th>\n",
              "      <td>3.20</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-04-23</th>\n",
              "      <td>7.70</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2008-10-08</th>\n",
              "      <td>3.57</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-04-29</th>\n",
              "      <td>8.39</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2009-10-14</th>\n",
              "      <td>3.89</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-04-28</th>\n",
              "      <td>9.16</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-10-13</th>\n",
              "      <td>4.37</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-04-27</th>\n",
              "      <td>10.09</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-10-12</th>\n",
              "      <td>4.63</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-04-25</th>\n",
              "      <td>10.13</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-10</th>\n",
              "      <td>4.63</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-04-24</th>\n",
              "      <td>10.13</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-10-09</th>\n",
              "      <td>4.63</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-04-30</th>\n",
              "      <td>10.13</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-10-30</th>\n",
              "      <td>1.16</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-10-12</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-05-17</th>\n",
              "      <td>2.00</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-10-11</th>\n",
              "      <td>1.67</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-05-16</th>\n",
              "      <td>4.10</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-10-10</th>\n",
              "      <td>2.65</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-21</th>\n",
              "      <td>6.50</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-15</th>\n",
              "      <td>3.20</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Dividends  Stock Splits\n",
              "Date                               \n",
              "1993-04-19       4.85           0.0\n",
              "1993-10-04       2.45           0.0\n",
              "1994-04-25       5.30           0.0\n",
              "1994-09-26       2.70           0.0\n",
              "1995-04-24       5.90           0.0\n",
              "1995-09-25       3.05           0.0\n",
              "1996-04-22       6.55           0.0\n",
              "1996-09-23       3.25           0.0\n",
              "1997-04-14       7.10           0.0\n",
              "1997-09-22       3.55           0.0\n",
              "1998-04-27       8.05           0.0\n",
              "1998-07-06       0.00           3.0\n",
              "1998-09-29       1.25           0.0\n",
              "1999-04-19       2.87           0.0\n",
              "1999-09-27       1.34           0.0\n",
              "2000-04-17       3.14           0.0\n",
              "2000-09-25       1.48           0.0\n",
              "2001-04-18       3.50           0.0\n",
              "2001-09-26       1.67           0.0\n",
              "2002-04-17       3.93           0.0\n",
              "2002-09-25       1.87           0.0\n",
              "2003-04-16       4.33           0.0\n",
              "2003-09-24       2.07           0.0\n",
              "2004-04-28       4.77           0.0\n",
              "2004-09-29       2.29           0.0\n",
              "2005-04-20       5.27           0.0\n",
              "2005-09-28       2.53           0.0\n",
              "2006-05-03       6.10           0.0\n",
              "2006-10-11       2.81           0.0\n",
              "2007-04-25       6.83           0.0\n",
              "2007-10-10       3.20           0.0\n",
              "2008-04-23       7.70           0.0\n",
              "2008-10-08       3.57           0.0\n",
              "2009-04-29       8.39           0.0\n",
              "2009-10-14       3.89           0.0\n",
              "2010-04-28       9.16           0.0\n",
              "2010-10-13       4.37           0.0\n",
              "2011-04-27      10.09           0.0\n",
              "2011-10-12       4.63           0.0\n",
              "2012-04-25      10.13           0.0\n",
              "2012-10-10       4.63           0.0\n",
              "2013-04-24      10.13           0.0\n",
              "2013-10-09       4.63           0.0\n",
              "2014-04-30      10.13           0.0\n",
              "2014-10-30       1.16           0.0\n",
              "2017-10-12       1.00           0.0\n",
              "2018-05-17       2.00           0.0\n",
              "2018-10-11       1.67           0.0\n",
              "2019-05-16       4.10           0.0\n",
              "2019-10-10       2.65           0.0\n",
              "2020-05-21       6.50           0.0\n",
              "2020-10-15       3.20           0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43A31PyneIi7"
      },
      "source": [
        "Analysts also frequently give recommendations whether to buy, sell or hold the stocks. This can be found by using the recommendations keyword. If there are no current recommentations, it will not return anything. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEJk4Q9EeFEf"
      },
      "source": [
        "tesco.recommendations\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEFZtb1oefmV"
      },
      "source": [
        "There are many other useful keywords we can use. A quick overview is given below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "wSAtplXaa5GO",
        "outputId": "0b7a76f0-9f6c-45f8-c86f-cc7eb7b6336c"
      },
      "source": [
        "\n",
        "\n",
        "# show actions (dividends, splits)\n",
        "tesco.actions\n",
        "\n",
        "# show dividends\n",
        "tesco.dividends\n",
        "\n",
        "# show splits\n",
        "tesco.splits\n",
        "\n",
        "# show financials\n",
        "tesco.financials\n",
        "tesco.quarterly_financials\n",
        "\n",
        "# show major holders\n",
        "tesco.major_holders\n",
        "\n",
        "# show institutional holders\n",
        "tesco.institutional_holders\n",
        "\n",
        "# show balance sheet\n",
        "tesco.balance_sheet\n",
        "tesco.quarterly_balance_sheet\n",
        "\n",
        "# show cashflow\n",
        "tesco.cashflow\n",
        "tesco.quarterly_cashflow\n",
        "\n",
        "# show earnings\n",
        "tesco.earnings\n",
        "tesco.quarterly_earnings\n",
        "\n",
        "# show sustainability\n",
        "tesco.sustainability\n",
        "\n",
        "# show analysts recommendations\n",
        "tesco.recommendations\n",
        "\n",
        "# show next event (earnings, etc)\n",
        "tesco.calendar\n",
        "\n",
        "# show ISIN code - *experimental*\n",
        "# ISIN = International Securities Identification Number\n",
        "tesco.isin\n",
        "\n",
        "# show options expirations\n",
        "tesco.options\n",
        "\n",
        "# get option chain for specific expiration\n",
        "opt = tesco.option_chain('YYYY-MM-DD')\n",
        "# data available via: opt.calls, opt.puts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bed313fe29f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# show options expirations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mtesco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# get option chain for specific expiration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/yfinance/ticker.py\u001b[0m in \u001b[0;36moptions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expirations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expirations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/yfinance/ticker.py\u001b[0m in \u001b[0;36m_download_options\u001b[0;34m(self, date, proxy)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 self._expirations[_datetime.datetime.utcfromtimestamp(\n\u001b[1;32m     60\u001b[0m                     exp).strftime('%Y-%m-%d')] = exp\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optionChain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'options'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LcuSBeKgBIp"
      },
      "source": [
        "# 2 - Scraping some extra data with selenium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFpBIvyngYYF"
      },
      "source": [
        "The yahoo finance API is great, but it doesn't always get what we want. If we go to the yahoo finance page for Tesco, we see that there are some things we don't have. Like the analyst price target, or the number of analysits who recommend buy, sell and hold. But we know webscraping now, so let's use that! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PyXCCyXgzYk"
      },
      "source": [
        "## 2.1 Set up selenium "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH6sYA7igTzX",
        "outputId": "5f5bf3be-835e-4f51-bb4c-e8a9a9e9d3b3"
      },
      "source": [
        "# setting up selenium \n",
        "\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "# copy the driver into the python path\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "# we use headless if we don't want to open a browser window that shows us what the driver is doing\n",
        "# in colab, it will only work if you're in headless\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "#we then use driver.get and the name of the webpage we want to use \n",
        "\n",
        "#driver.get(\"https://www.webite-url.com\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\r\u001b[K     |▍                               | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 11.1MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 7.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 6.9MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 71kB 4.9MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 102kB 5.5MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 5.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 122kB 5.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 133kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 143kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 153kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 163kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 174kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 184kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 194kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 204kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 215kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████                        | 225kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 235kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 245kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████                       | 256kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 266kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 276kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 286kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 296kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 307kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 317kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 327kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 337kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 348kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 358kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 368kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 378kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 389kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 399kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 409kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 419kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 430kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 440kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 450kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 460kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 471kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 481kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 491kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 501kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 512kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 522kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 532kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 542kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 552kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 563kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 573kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 583kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 593kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 604kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 614kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 624kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 634kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 645kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 655kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 665kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 675kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 686kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 696kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 706kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 716kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 727kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 737kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 747kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 757kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 768kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 778kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 788kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 798kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 808kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 819kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 829kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 839kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 849kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 860kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 870kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 880kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 890kB 5.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 901kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 911kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [443 kB]\n",
            "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,781 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,690 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,130 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,365 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,208 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [252 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [54.3 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [865 kB]\n",
            "Get:23 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [46.5 kB]\n",
            "Fetched 11.1 MB in 6s (1,749 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 60 not upgraded.\n",
            "Need to get 80.2 MB of archives.\n",
            "After this operation, 272 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 86.0.4240.198-0ubuntu0.18.04.1 [1,126 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 86.0.4240.198-0ubuntu0.18.04.1 [71.0 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 86.0.4240.198-0ubuntu0.18.04.1 [3,585 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 86.0.4240.198-0ubuntu0.18.04.1 [4,492 kB]\n",
            "Fetched 80.2 MB in 9s (9,114 kB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_86.0.4240.198-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (86.0.4240.198-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_86.0.4240.198-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (86.0.4240.198-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_86.0.4240.198-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (86.0.4240.198-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_86.0.4240.198-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (86.0.4240.198-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (86.0.4240.198-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (86.0.4240.198-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (86.0.4240.198-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (86.0.4240.198-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: use options instead of chrome_options\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBIMyrm5g3nu"
      },
      "source": [
        "## 2.2 Access our webpage "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3LVCGVRg2Gc"
      },
      "source": [
        "driver.get(\"https://uk.finance.yahoo.com/quote/TSCO.L?p=TSCO.L&.tsrc=fin-srch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9UpVqiBHGu1"
      },
      "source": [
        "# we need to agree to cookies before it lets us into their page! \n",
        "driver.find_element_by_xpath('//*[@id=\"consent-page\"]/div/div/div/div[2]/div[2]/form/button').click()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7cCP-VI250Y"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsV-FCe_2UPX"
      },
      "source": [
        "# we need to scroll down on the page a bit before we get to the relevant part. This is important, otherwise the right html won't be loaded into our driver\n",
        "\n",
        "old_position = 0\n",
        "new_position = None\n",
        "\n",
        "# this scrolls to the bottom of the page \n",
        "while new_position != old_position:\n",
        "    # Get old scroll position\n",
        "    old_position = driver.execute_script(\n",
        "            (\"return (window.pageYOffset !== undefined) ?\"\n",
        "            \" window.pageYOffset : (document.documentElement ||\"\n",
        "            \" document.body.parentNode || document.body);\"))\n",
        "    # Sleep and Scroll\n",
        "    time.sleep(1)\n",
        "    driver.execute_script((\n",
        "            \"var scrollingElement = (document.scrollingElement ||\"\n",
        "            \" document.body);scrollingElement.scrollTop =\"\n",
        "            \" scrollingElement.scrollHeight;\"))\n",
        "    # Get new position\n",
        "    new_position = driver.execute_script(\n",
        "            (\"return (window.pageYOffset !== undefined) ?\"\n",
        "            \" window.pageYOffset : (document.documentElement ||\"\n",
        "            \" document.body.parentNode || document.body);\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzdf4mEVL8F9"
      },
      "source": [
        "# I have checked the html and found the expath for the low analyst price target \n",
        "\n",
        "low_target = driver.find_element_by_xpath('/html/body/div[1]/div/div/div[1]/div/div[3]/div[2]/div/div/div/div/div/div[10]/div/div/div/section/div/div[2]/div[1]/span[2]')\n",
        "\n",
        "# see if you can do the same with the high target and the average target \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbt1yhTV3GRW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bab490b7-165d-4ebc-a5d2-30b2560cbca6"
      },
      "source": [
        "# by getting the attribute of the inner HTML, we see what it contains, which here is the price \n",
        "low_target.get_attribute('innerHTML')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'200.00'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvmlK5-x6etg"
      },
      "source": [
        "# doing them same for the esg risk \n",
        "esg_risk = driver.find_element_by_xpath('/html/body/div[1]/div/div/div[1]/div/div[3]/div[2]/div/div/div/div/div/div[4]/div/div/div/section/div[2]/div/div/div[1]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeYnbr7C6pRE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f6188828-72af-4699-8c2b-1a1dea779ca3"
      },
      "source": [
        "esg_risk.get_attribute('innerHTML')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'18.5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_E3cADJScLh"
      },
      "source": [
        "# 3 - Finnhub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giMVtQo9SrP2"
      },
      "source": [
        "We still couldn't get the recommendations for buy, sell etc. from Yahoo finance because this is stored in a picture. We can use another free API for this, the Finnhub API. This has some limits for the free version. We are limited 30 API call/second, but this won't be a huge issue for us. If you want to explore the American markets, you will probably want to use Finnhub quite a lot. It can give you company news, market news, forex, crypto and much more. A lot of this is limited to the American markets when we are using the free API. \n",
        "\n",
        "\n",
        "To use the Finnhub API, you will need to create a token. Do this by going to the [Finnhub webpage](https://finnhub.io/)\n",
        "and click *Get free API key* . You will need to create an account, again feel free to use your citylit account here, if you want. This will take you to a page where it shows your API key. Copy this - you will need it a few cells further down. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHE9AhT1FBwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60084a79-2b3b-47e6-f088-400348356b49"
      },
      "source": [
        "# need to install finnhub \n",
        "!pip install finnhub-python\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting finnhub-python\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a6/905724e1e32abdbe91d121bd0634be20aae532d8bcebc8d41821d6cb7033/finnhub_python-2.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from finnhub-python) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->finnhub-python) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->finnhub-python) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->finnhub-python) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->finnhub-python) (1.24.3)\n",
            "Installing collected packages: finnhub-python\n",
            "Successfully installed finnhub-python-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzg1OLxVFA_C"
      },
      "source": [
        "#load finnhub\n",
        "\n",
        "import finnhub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8PsjCjbhAw7"
      },
      "source": [
        "my_api_key = 'yourkeyhere!'\n",
        "# Setup client - you need to paste your own api_key here! \n",
        "finnhub_client = finnhub.Client(api_key=my_api_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKatCoYyQgwA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "004907f9-1fd5-43d5-9d7e-bc22cad841a3"
      },
      "source": [
        "# requests is a package for requesting webpages \n",
        "import requests\n",
        "\n",
        "# In this example, we request the webpage where the stock recommendations are stored. In this link, we have symbol=TSCO.L\n",
        "# what comes after the symbol= is the ticker. When you want to change this for ofther companies, you can e.g. create a variable called ticker and put it there \n",
        "r = requests.get('https://finnhub.io/api/v1/stock/recommendation?symbol=TSCO.L&token='+my_api_key)\n",
        "# the result is a dictionary that has the recommendations for certain time periods \n",
        "print(r.json())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-ebc7857b750a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://finnhub.io/api/v1/stock/recommendation?symbol=TSCO.L&token='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmy_api_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# the result is a dictionary that has the recommendations for certain time periods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0;31m# used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak91XXTxWJSn"
      },
      "source": [
        "You can also get the tickers from different markets using Finnhub. You can have a think about what you want to predict. If you for instance want to predict the stocks on the London stock exchange, you can find all the relevant tickers by doing the below. If you want tickers from other exchanges, have a look at the list of avaliable indices and their abbreviations within Finnhub [here](https://docs.google.com/spreadsheets/d/1I3pBxjfXB056-g_JYf_6o3Rns3BV2kMGG1nCatb91ls/edit#gid=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H6B-MXEGm_O"
      },
      "source": [
        "# the exchange is specified in this link as exchange=L\n",
        "# L is london  - if you need others, have \n",
        "\n",
        "r = requests.get('https://finnhub.io/api/v1/stock/symbol?exchange=L&token=bu7cue748v6uhfp5q5s0')\n",
        "df = pd.DataFrame(r.json())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft4vtOZMSIRc"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRrGbIhLXUQq"
      },
      "source": [
        "# 4 - Decide what you want to predict! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NEZzOyuXao5"
      },
      "source": [
        "Now you have access to a lot of cool data. Remember to use the news notebook to combine the news as well. You are free to choose what you want to predict. It could for instance be a specific index, a few specific stocks, or a specific industry. You will also need to choose which time period you want to predict over. This depends on how you would be trading. Would you want to trade every day, every week, month or year? Depending on your answer to this, you can predict the next day price, the average price over a week, the max price over a week, the change in price, and so on. It is worth giving this a lot of thought early on, becuase this will very much affect your data cleaning and processing. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-KCDohFYehO"
      },
      "source": [
        "# 5 - Getting even more data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XScqOhe4Z51J"
      },
      "source": [
        "As we discovered, the Yahoo finance API is a little bit limited in that only stores about 170 or so articles for each company. I still prefer using yahoo finance because we get the articles by the company ticker, so we are absolutely sure we are getting the right results. However, if you feel the number of articles is limiting you, we can use other apis. One alternative is datanews, where you get 3000 free API calls a month. This could also potentially be a limit, depending on what you want to do. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23E6yWhTXSB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efd1e21f-cb3f-49f5-bc76-92e451a4e375"
      },
      "source": [
        "! pip install datanews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datanews\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/61/17def7528f3d2e07a5df4122f1bea62595bd9e915851dfb3935960442635/datanews-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from datanews) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from datanews) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->datanews) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->datanews) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->datanews) (2.10)\n",
            "Installing collected packages: datanews\n",
            "Successfully installed datanews-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWkFkxDqoV3N"
      },
      "source": [
        "The below gives us a very basic example of their api. As with finnhub, you need to sign up, and use your own API key below. You can sign up [here](https://datanews.io/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnBW--yja4kt",
        "outputId": "a2620f68-85e0-45ad-9b8f-539ee324d939"
      },
      "source": [
        "import datanews\n",
        "#your key goes here!!  \n",
        "datanews.api_key = '050085f0cxslgxpvwqkjp3ops'\n",
        "\n",
        "response = datanews.headlines(q='Beyond meat',language=['en'])\n",
        "articles = response['hits']\n",
        "print(articles[0]['title'])\n",
        "\n",
        "datanews.headlines"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beyond Meat Introduces Beyond Pork in China - TheStreet\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function datanews.api_resources.news.headlines>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VbYJfk3bUb6",
        "outputId": "23d57f6d-53bf-4a60-862f-bf15d4ca15a9"
      },
      "source": [
        "articles"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'authors': ['Dan Weil'],\n",
              "  'content': 'Beyond Meat, the plant-based meat company that is riding the health-food boom, said it was selling a pork product in China.\\n\\nBeyond Meat (BYND) - Get Report, the plant-based meat company that is riding the health-food boom, said on Wednesday it’s sel ... [+1947 chars]',\n",
              "  'country': 'us',\n",
              "  'description': 'Beyond Meat Introduces Beyond Pork in China  TheStreet',\n",
              "  'imageUrl': 'https://www.thestreet.com/.image/t_share/MTczNjU3NzgxNTg3NDIxMTU4/beyond-meat.jpg',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-18T14:15:00+00:00',\n",
              "  'source': 'thestreet.com',\n",
              "  'title': 'Beyond Meat Introduces Beyond Pork in China - TheStreet',\n",
              "  'url': 'https://www.thestreet.com/investing/beyond-meat-unveils-beyond-pork-in-china'},\n",
              " {'authors': ['Chris DeMuth Jr.'],\n",
              "  'content': 'New flavor, new cooking instructions, and new guidance (something must have been terribly wrong with the previous flavor, cooking instructions, and guidance). The new guidance is.. no guidance on Q4 and the fiscal year. Beyond Meat’s (BYND) quarterly ... [+5789 chars]',\n",
              "  'country': 'us',\n",
              "  'description': 'Beyond Beyond Meat  Seeking Alpha',\n",
              "  'imageUrl': 'https://static3.seekingalpha.com/assets/og_image_192-59bfd51c9fe6af025b2f9f96c807e46f8e2f06c5ae787b15bf1423e6c676d4db.png',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-11T14:30:00+00:00',\n",
              "  'source': 'seekingalpha.com',\n",
              "  'title': 'Beyond Beyond Meat - Seeking Alpha',\n",
              "  'url': 'https://seekingalpha.com/article/4387899-beyond-beyond-meat'},\n",
              " {'authors': ['Cristine Struble'],\n",
              "  'content': 'New Beyond Burger options show that Beyond Meat is the leader plant-based food category.\\n\\nThe new year will bring new Beyond Burger options. While Beyond Meat is always looking to expand its plant-based food options, this newest innovation responds t ... [+2420 chars]',\n",
              "  'country': 'us',\n",
              "  'description': 'Beyond Meat unveils two new Beyond Burger options  FoodSided',\n",
              "  'imageUrl': 'https://images2.minutemediacdn.com/image/fetch/w_2000,h_2000,c_fit/https%3A%2F%2Ffoodsided.com%2Ffiles%2F2020%2F11%2FNew-Beyond-Burger-Hero.jpg',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-16T18:14:47+00:00',\n",
              "  'source': 'foodsided.com',\n",
              "  'title': 'Beyond Meat unveils two new Beyond Burger options - FoodSided',\n",
              "  'url': 'https://foodsided.com/2020/11/16/beyond-meat-unveils-new-beyond-burger-options/'},\n",
              " {'authors': ['Dana Blankenhorn'],\n",
              "  'content': 'Why Beyond Meat Stock Remains Beyond Perilous',\n",
              "  'country': 'us',\n",
              "  'description': 'Why Beyond Meat Stock Remains Beyond Perilous  InvestorPlace',\n",
              "  'imageUrl': 'https://investorplace.com/wp-content/uploads/2019/08/bynd-stock-1.jpg',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-20T15:55:00+00:00',\n",
              "  'source': 'investorplace.com',\n",
              "  'title': 'Why Beyond Meat Stock Remains Beyond Perilous - InvestorPlace',\n",
              "  'url': 'https://investorplace.com/2020/11/beyond-meat-stock-perilous/'},\n",
              " {'authors': [],\n",
              "  'content': 'This week, California-based vegan brand Beyond Meat unveiled a new product, Beyond Pork, which is made specifically for Chinese consumers. The ground vegan pork was created to be used as a filling in dumplings and spring rolls, as well as in dishes s ... [+1829 chars]',\n",
              "  'country': 'us',\n",
              "  'description': 'Beyond Meat Creates New Vegan Product for China: Beyond Pork  VegNews',\n",
              "  'imageUrl': 'https://vegnews.com/media/W1siZiIsIjIwNTQ1L1ZlZ05ld3MuQmV5b25kUG9ya0NoaW5hLmpwZyJdLFsicCIsInRodW1iIiwiODAweDQ3MyMiLHsiZm9ybWF0IjoianBnIn1dLFsicCIsIm9wdGltaXplIl1d/VegNews.BeyondPorkChina.jpg?width=800&height=473&optimize=true&format=jpg&sha=6d508161e64da11c',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-19T13:06:29+00:00',\n",
              "  'source': 'vegnews.com',\n",
              "  'title': 'Beyond Meat Creates New Vegan Product for China: Beyond Pork - VegNews',\n",
              "  'url': 'https://vegnews.com/2020/11/beyond-meat-creates-new-vegan-product-for-china-beyond-pork'},\n",
              " {'authors': [],\n",
              "  'content': 'Los Angeles-based Beyond Meat’s expansion to the People’s Republic of China announced in early September, is already taking shape with a new product roll-out for the Chinese market.\\n\\nFrom Shanghai, Beyond Meat officials said their newest product prod ... [+3803 chars]',\n",
              "  'country': 'us',\n",
              "  'description': \"Beyond Meat introduces 'Beyond Pork' for Chinese market  Food Safety News\",\n",
              "  'imageUrl': 'https://www.foodsafetynews.com/files/2020/09/Beyond1200x680.jpg',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-20T05:18:47+00:00',\n",
              "  'source': 'foodsafetynews.com',\n",
              "  'title': \"Beyond Meat introduces 'Beyond Pork' for Chinese market - Food Safety News\",\n",
              "  'url': 'https://www.foodsafetynews.com/2020/11/beyond-meat-introduces-beyond-pork-for-chinese-market/'},\n",
              " {'authors': ['The Motley Fool'],\n",
              "  'content': \"Shares of Beyond Meat (NASDAQ: BYND) dropped today after Bernstein analyst Alexia Howard said it will underperform the market and lowered the stock's price target. This reputable analyst's bearish sentiment has retail investors reconsidering their po ... [+2311 chars]\",\n",
              "  'country': '',\n",
              "  'description': 'Why Beyond Meat Stock Dropped Today  Nasdaq',\n",
              "  'imageUrl': 'https://www.nasdaq.com/sites/acquia.prod/files/2019-05/0902-Q19%20Total%20Markets%20photos%20and%20gif_CC8.jpg?2136152636',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-10-13T14:48:00+00:00',\n",
              "  'source': 'nasdaq.com',\n",
              "  'title': 'Why Beyond Meat Stock Dropped Today - Nasdaq',\n",
              "  'url': 'https://www.nasdaq.com/articles/why-beyond-meat-stock-dropped-today-2020-10-13'},\n",
              " {'authors': ['Sophie Hirsh'],\n",
              "  'content': 'The Beyond Burger is a near-perfect plant-based clone of a beef burger, but Beyond Meat wants it to be absolutely perfect. So, the vegan brand has two new Beyond Burgers heading to market: one designed to be even meatier than the original, and one th ... [+3283 chars]',\n",
              "  'country': 'us',\n",
              "  'description': 'Beyond Meat Is Dropping Two New Beyond Burgers  Green Matters',\n",
              "  'imageUrl': 'https://media.greenmatters.com/brand-img/6pBmI334B/0x0/beyond-meat-new-burgers-1605543893372.jpg',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-16T16:25:00+00:00',\n",
              "  'source': 'greenmatters.com',\n",
              "  'title': 'Beyond Meat Is Dropping Two New Beyond Burgers - Green Matters',\n",
              "  'url': 'https://www.greenmatters.com/p/beyond-meat-meatier-low-fat'},\n",
              " {'authors': [],\n",
              "  'content': 'Beyond Meat and other plant-based protein makers have the potential to win over health-conscious customers, but often have similar nutritional value to traditional meat.\\n\\n\"I am personally thrilled to introduce this new Beyond Burger platform as it sp ... [+1711 chars]',\n",
              "  'country': 'us',\n",
              "  'description': 'Beyond Meat unveils two new versions of its Beyond Burgers  ClickLancashire',\n",
              "  'imageUrl': '',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-17T01:30:30+00:00',\n",
              "  'source': 'clicklancashire.com',\n",
              "  'title': 'Beyond Meat unveils two new versions of its Beyond Burgers - ClickLancashire',\n",
              "  'url': 'https://clicklancashire.com/2020/11/17/beyond-meat-unveils-two-new-versions-of-its-beyond-burgers.html'},\n",
              " {'authors': ['Daniel Schönberger'],\n",
              "  'content': \"So far, I covered Beyond Meat (BYND) twice - the first time in June 2019 a few weeks after the company's IPO and again in January 2020. In both cases, I have been very bearish about the stock - and I am still bearish although the stock has seen much  ... [+14080 chars]\",\n",
              "  'country': 'us',\n",
              "  'description': 'Beyond Meat, But Troubles Ahead  Seeking Alpha',\n",
              "  'imageUrl': 'https://static3.seekingalpha.com/assets/og_image_192-59bfd51c9fe6af025b2f9f96c807e46f8e2f06c5ae787b15bf1423e6c676d4db.png',\n",
              "  'language': 'en',\n",
              "  'pubDate': '2020-11-18T13:07:00+00:00',\n",
              "  'source': 'seekingalpha.com',\n",
              "  'title': 'Beyond Meat, But Troubles Ahead - Seeking Alpha',\n",
              "  'url': 'https://seekingalpha.com/article/4389964-beyond-meat-troubles-ahead'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBhI4zBAobp9"
      },
      "source": [
        "What we will likely do, though, is to do more complex searches, specifically using a specified time frame. The documentation for datanews uses curl. curl is used in command lines or scripts to transfer data. In Python, we usually use request. I have translated the datanews curl commands into python, so you can alter the example below as you see fit. \n",
        "\n",
        "You can add other parameters in the same way. You can look at the extra parameters available [here](https://datanews.io/docs/news)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47MMJxd8iu-r"
      },
      "source": [
        "import requests\n",
        "\n",
        "#YOUR OWN API KEY WILL GO HERE \n",
        "headers = {\n",
        "    'x-api-key': '050085f0cxslgxpvwqkjp3ops',\n",
        "}\n",
        "\n",
        "params = (\n",
        "    #the query is what we are searching for \n",
        "    ('q', 'Sainsbury'),\n",
        "    ('from', '2016-07-01'),\n",
        "    ('to', '2019-12-01'),\n",
        "    ('language', 'en')\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "response = requests.get('http://api.datanews.io/v1/news', headers=headers, params=params)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmn3uEw2i8j-",
        "outputId": "04eb166e-40ab-4d86-ccfc-de09a42cb710"
      },
      "source": [
        "# the response here is a java script format \n",
        "# it is a dictionary of dictionaries \n",
        "response.json()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hits': [{'authors': ['Bethany Alice Papworth'],\n",
              "   'content': 'THE busiest time of the year to bag a supermarket delivery slot is at Christmas.\\n\\nTo avoid disappointment, supermarkets have been letting shoppers book delivery slots from the start of November.\\n\\nWhen these delivery slots do become available, they ca ... [+3542 chars]',\n",
              "   'country': 'gb',\n",
              "   'description': 'THE busiest time of the year to bag a supermarket delivery slot is at Christmas. To avoid disappointment, supermarkets are letting you book delivery slots as early as the start of November.',\n",
              "   'imageUrl': 'https://www.thescottishsun.co.uk/wp-content/uploads/sites/2/2019/11/D01BX4jpg-JS341170895-1.jpg?strip=all&quality=100&w=1064&h=708&crop=1',\n",
              "   'language': 'en',\n",
              "   'pubDate': '2019-11-11T12:12:55+00:00',\n",
              "   'source': 'thescottishsun.co.uk',\n",
              "   'title': \"Christmas delivery slots 2019 - when can to book Tesco, Asda, Morrisons, Sainsbury's, Waitrose, Ocado and Iceland\",\n",
              "   'url': 'https://www.thescottishsun.co.uk/money/4941129/when-will-christmas-delivery-slots-2019-open-for-tesco-asda-morrisons-sainsbury-waitrose-and-ocado/'},\n",
              "  {'authors': ['Ottoline Leyser'],\n",
              "   'content': 'Reproducibility is the idea that an experiment can be repeated by another scientist and they will get the same result. It is important to show that the claims of any experiment are true and for them to be useful for any further research.\\n\\nHowever, sc ... [+7750 chars]',\n",
              "   'country': 'us',\n",
              "   'description': 'Reproducibility is the idea that an experiment can be repeated by another scientist and they will get the same result. It is important to show that the claims of any experiment are true and for them to be useful for any further research.',\n",
              "   'imageUrl': 'https://scx2.b-cdn.net/gfx/news/hires/2017/thesciencere.jpg',\n",
              "   'language': 'en',\n",
              "   'pubDate': '2017-03-15T12:10:01+00:00',\n",
              "   'source': 'phys.org',\n",
              "   'title': \"The science 'reproducibility crisis' – and what can be done about it\",\n",
              "   'url': 'https://phys.org/news/2017-03-science-crisis.html'}],\n",
              " 'numResults': 2,\n",
              " 'status': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL_e_3l3qXu8"
      },
      "source": [
        "We now want to get the urls from the dictionaries. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkqq1PI2nB5n",
        "outputId": "de2882ff-80d1-4829-e0d1-c20121edda21"
      },
      "source": [
        "links = []\n",
        "dates = []\n",
        "\n",
        "# all of the data is stored in the key hits \n",
        "for dictionary in response.json()['hits']: \n",
        "    # for each hit, we get the value stored in the key url \n",
        "    url = dictionary['url']\n",
        "    # and we then append it to the links we found\n",
        "    links.append(url)\n",
        "    # we probably want to create a list of all the dates as well\n",
        "    dates.append(dictionary['pubDate'])\n",
        "\n",
        "#response.json()['hits']\n",
        "\n",
        "links"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://www.ccn.com/beyond-meat-tanks-13-percent-because-of-this-terrible-news/',\n",
              " 'https://www.timesofisrael.com/poland-will-end-its-kosher-and-halal-meat-export-industry-in-2025/',\n",
              " 'https://www.ibtimes.com/wheres-beef-mcdonalds-test-new-beyond-meat-burger-canada-2834005',\n",
              " 'https://www.rte.ie/archives/2019/0930/1079179-mister-meat-loaf/',\n",
              " 'https://www.marketwatch.com/story/what-nutrition-experts-are-saying-about-imitation-meats-in-your-diet-2019-11-25?mod=home-page',\n",
              " 'https://food.ndtv.com/video-andhra-crab-meat-masala-recipe-528213',\n",
              " 'https://www.richmond-news.com/standout/buying-meat-the-old-fashioned-way-ensures-taste-and-quality-1.23931400',\n",
              " 'https://www.wired.com/story/the-meat-allergy-tick-also-carries-a-mystery-killer-virus/',\n",
              " 'https://www.ccn.com/no-mans-sky-beyond-ride-aliens/',\n",
              " 'https://www.eater.com/2019/10/11/20909222/impossible-meat-future-war-ceo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sItiwGAcBVDX"
      },
      "source": [
        "Now say that we had a list of companies that we want to get news for. We need to find a good way to append that data. There are \n",
        "sevral ways of doing it. I think pandas is probably the easiest to read. The downside is that if you have huge panda, it might get slow and the panda grows fat. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDQqW5n2Bj1K"
      },
      "source": [
        "## 5.2 - Appending data to a panda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzPYkXLlNiK5"
      },
      "source": [
        "Usually I like to write a high level function. Makes it easy, and makes things reusable. Also note a very important point here. When we start to append lots of data - don't append straight to a panda. Append to a list, and then make a panda. It is a lot more efficient!! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckIQvf9JCLKQ"
      },
      "source": [
        "\n",
        "def getNews_dataNews(tickers, searchTerms): \n",
        "    \n",
        "    \"\"\" Inputs: list of tickers, list of search terms\n",
        "        Outputs: a data frame with the ticker, date, title and urls \n",
        "    \"\"\" \n",
        "\n",
        "    results = []\n",
        "    # zip zips the lists together like a zipper \n",
        "    for ticker, searchTerm in zip(tickers, searchTerms):\n",
        "\n",
        "        headers = {\n",
        "            # YOUR API KEY HERE\n",
        "            'x-api-key': '',\n",
        "        }   \n",
        "\n",
        "        params = (\n",
        "            #the query is what we are searching for \n",
        "            ('q', searchTerm),\n",
        "            ('from', '2016-07-01'),\n",
        "            ('to', '2019-12-01'),\n",
        "            ('language', 'en')\n",
        "        )\n",
        "\n",
        "\n",
        "        response = requests.get('http://api.datanews.io/v1/news', headers=headers, params=params)\n",
        "\n",
        "        # all of the data is stored in the key hits \n",
        "        for dictionary in response.json()['hits']: \n",
        "            results.append([ticker, dictionary['pubDate'],  dictionary['title'], dictionary['url']])\n",
        "\n",
        "    final_result_df = pd.DataFrame(results, columns=['ticker', 'pubDate', 'title', 'url'])\n",
        "    return(final_result_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMd0WGcWEPq8"
      },
      "source": [
        "# time to rap the benefits of our high quality function\n",
        "\n",
        "tickerList = ['TSCO.L', 'SBRY.L', 'OCDO.L']\n",
        "searchTermList = ['Tesco', 'Sainsbury', 'Ocado']\n",
        "\n",
        "superMarketNews = getNews_dataNews(tickerList, searchTermList)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boXJXrUeHp_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "81e74390-efef-4d6f-8778-ed829a5ed26d"
      },
      "source": [
        "superMarketNews"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>pubDate</th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2018-09-09T00:00:00+00:00</td>\n",
              "      <td>Tesco deal bodes ill for business</td>\n",
              "      <td>https://www.bangkokpost.com/business/2018099/t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2019-08-14T07:28:30+00:00</td>\n",
              "      <td>Triple Credit - TV and Broadband ISP NOW TV Pa...</td>\n",
              "      <td>https://www.ispreview.co.uk/index.php/2019/08/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2019-08-06T04:47:00+00:00</td>\n",
              "      <td>Fresh redundancies as Tesco cuts 4,500 jobs at...</td>\n",
              "      <td>//www.theweek.co.uk/102629/fresh-redundancies-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2018-05-22T14:36:31+00:00</td>\n",
              "      <td>Tesco Direct is closing next month as it slash...</td>\n",
              "      <td>https://www.thescottishsun.co.uk/money/2680332...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2019-11-11T12:12:55+00:00</td>\n",
              "      <td>Christmas delivery slots 2019 - when can to bo...</td>\n",
              "      <td>https://www.thescottishsun.co.uk/money/4941129...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2016-08-23T00:00:00+00:00</td>\n",
              "      <td>Limit set for CP to appeal deal ruling</td>\n",
              "      <td>https://www.bangkokpost.com/business/2016823/l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2018-09-26T05:30:48+00:00</td>\n",
              "      <td>FCA fine Tesco Bank over cyber breach</td>\n",
              "      <td>https://www.fintechinshorts.com/fca-fine-tesco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2018-09-26T05:30:48+00:00</td>\n",
              "      <td>FCA fine Tesco Bank over cyber breach</td>\n",
              "      <td>https://www.fintechinshorts.com/fca-fine-tesco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2019-03-09T19:07:09+00:00</td>\n",
              "      <td>PRWeek UK Power Book 2019: New Tesco comms chi...</td>\n",
              "      <td>https://www.prweek.com/article/1578449/prweek-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TSCO.L</td>\n",
              "      <td>2018-10-10T10:23:05.900000+00:00</td>\n",
              "      <td>Tesco Is Selling Cocoa-Cola Cinnamon For The F...</td>\n",
              "      <td>https://www.bustle.com/life/where-to-buy-cinna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SBRY.L</td>\n",
              "      <td>2019-11-11T12:12:55+00:00</td>\n",
              "      <td>Christmas delivery slots 2019 - when can to bo...</td>\n",
              "      <td>https://www.thescottishsun.co.uk/money/4941129...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SBRY.L</td>\n",
              "      <td>2017-03-15T12:10:01+00:00</td>\n",
              "      <td>The science 'reproducibility crisis' – and wha...</td>\n",
              "      <td>https://phys.org/news/2017-03-science-crisis.html</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2019-02-27T07:29:48+00:00</td>\n",
              "      <td>Is Ocado coming to Scotland at last?</td>\n",
              "      <td>https://www.insider.co.uk/news/marks--spencer-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2019-11-11T12:12:55+00:00</td>\n",
              "      <td>Christmas delivery slots 2019 - when can to bo...</td>\n",
              "      <td>https://www.thescottishsun.co.uk/money/4941129...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2019-07-06T09:00:00+00:00</td>\n",
              "      <td>Government teams up with supermarkets to map p...</td>\n",
              "      <td>//www.autoexpress.co.uk/news/107264/government...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2018-07-05T16:08:00+00:00</td>\n",
              "      <td>Nine Lower Mainland Safeway stores close today...</td>\n",
              "      <td>http://www.vancourier.com/news/nine-lower-main...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2018-07-05T16:08:00+00:00</td>\n",
              "      <td>Nine Lower Mainland Safeway stores close today...</td>\n",
              "      <td>https://www.vancourier.com/news/nine-lower-mai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2018-11-02T15:46:24+00:00</td>\n",
              "      <td>Ruffer made 23% in the 2008 crash, so where is...</td>\n",
              "      <td>https://www.thisismoney.co.uk/money/investings...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2018-11-02T15:46:24+00:00</td>\n",
              "      <td>Ruffer made 23% in the 2008 crash, so where is...</td>\n",
              "      <td>https://www.thisismoney.co.uk/money/investings...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2018-11-02T15:46:24+00:00</td>\n",
              "      <td>Ruffer made 23% in the 2008 crash, so where is...</td>\n",
              "      <td>https://www.thisismoney.co.uk/money/investings...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2018-07-12T00:00:00+00:00</td>\n",
              "      <td>Chris Bryant - Rolls-Royce Is Fast Becoming a ...</td>\n",
              "      <td>https://english.aawsat.com/home/article/249514...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>OCDO.L</td>\n",
              "      <td>2019-07-01T11:38:49+00:00</td>\n",
              "      <td>13 best plastic free tea bags to make your bre...</td>\n",
              "      <td>http://independent.co.uk/extras/indybest/food-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ticker  ...                                                url\n",
              "0   TSCO.L  ...  https://www.bangkokpost.com/business/2018099/t...\n",
              "1   TSCO.L  ...  https://www.ispreview.co.uk/index.php/2019/08/...\n",
              "2   TSCO.L  ...  //www.theweek.co.uk/102629/fresh-redundancies-...\n",
              "3   TSCO.L  ...  https://www.thescottishsun.co.uk/money/2680332...\n",
              "4   TSCO.L  ...  https://www.thescottishsun.co.uk/money/4941129...\n",
              "5   TSCO.L  ...  https://www.bangkokpost.com/business/2016823/l...\n",
              "6   TSCO.L  ...  https://www.fintechinshorts.com/fca-fine-tesco...\n",
              "7   TSCO.L  ...  https://www.fintechinshorts.com/fca-fine-tesco...\n",
              "8   TSCO.L  ...  https://www.prweek.com/article/1578449/prweek-...\n",
              "9   TSCO.L  ...  https://www.bustle.com/life/where-to-buy-cinna...\n",
              "10  SBRY.L  ...  https://www.thescottishsun.co.uk/money/4941129...\n",
              "11  SBRY.L  ...  https://phys.org/news/2017-03-science-crisis.html\n",
              "12  OCDO.L  ...  https://www.insider.co.uk/news/marks--spencer-...\n",
              "13  OCDO.L  ...  https://www.thescottishsun.co.uk/money/4941129...\n",
              "14  OCDO.L  ...  //www.autoexpress.co.uk/news/107264/government...\n",
              "15  OCDO.L  ...  http://www.vancourier.com/news/nine-lower-main...\n",
              "16  OCDO.L  ...  https://www.vancourier.com/news/nine-lower-mai...\n",
              "17  OCDO.L  ...  https://www.thisismoney.co.uk/money/investings...\n",
              "18  OCDO.L  ...  https://www.thisismoney.co.uk/money/investings...\n",
              "19  OCDO.L  ...  https://www.thisismoney.co.uk/money/investings...\n",
              "20  OCDO.L  ...  https://english.aawsat.com/home/article/249514...\n",
              "21  OCDO.L  ...  http://independent.co.uk/extras/indybest/food-...\n",
              "\n",
              "[22 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    }
  ]
}